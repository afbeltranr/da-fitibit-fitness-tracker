{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Exploring the fit bit kaggle dataset \n",
    "\n",
    "This notebook aims to explore and analyze the Fitbit dataset. The dataset contains various CSV files with information on daily activities, calories burned, heart rate, sleep patterns, and more. We will start by listing the directory structure of the dataset, then proceed to load and inspect some key CSV files. Basic statistics and visualizations will be generated to understand the data better.\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "1. [Ask](#Ask)\n",
    "   - [Accessing the Kaggle Dataset](#accessing-the-kaggle-dataset)\n",
    "   - [Data Exploration](#data-exploration)\n",
    "2. [Prepare](#prepare)\n",
    "3. [Process](#process)\n",
    "4. [Analyze](#analyze)\n",
    "5. [Share](#share)\n",
    "6. [Act](#act)\n",
    "\n",
    "\n",
    "# Ask\n",
    "[Back to Table of Contents](#table-of-contents)\n",
    "\n",
    "\n",
    "The business task is to use the Fitbit Fitness Tracker Data to analyze trends in users‚Äô daily habits and provide insights to help guide marketing strategy for Bellabeat. The main questions to guide the analysis are:\n",
    "\n",
    "1. What are some trends in smart device usage?\n",
    "2. How could these trends apply to Bellabeat customers?\n",
    "3. How could these trends help influence Bellabeat marketing strategy?\n",
    "\n",
    "The key stakeholders are Ur≈°ka Sr≈°en ‚Äì cofounder and Chief Creative Officer; Sando Mur ‚Äì cofounder and key member of the executive team.\n",
    "\n",
    "# Prepare \n",
    "\n",
    "Deliverable: A description of all data sources used.\n",
    "\n",
    "\n",
    "\n",
    "## Accessing the Kaggle Dataset\n",
    "[Back to Table of Contents](#table-of-contents)\n",
    "\n",
    "This repository includes a GitHub Actions workflow that continuously tests the process of connecting to the Kaggle API, using github secrets to pass username and key securely as environment variables to the automated workflow, and then checks if the files are correctly downloaded and unzipped, if so, a CSV file is imported and printed using pandas.\n",
    "\n",
    "In this research notebook we will use an analogue operation to gather the dataset, but instead of using secrets, the machine that runs this notebook looks for the kaggle.json file that should be in the .kaggle/ folder, to authenticate and download the file. (This file should be included in the .gitignore file, so it's not commited/shared).\n",
    "\n",
    "We can make sure all libraries for this step are imported:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # to create the directory\n",
    "import kaggle # To download the dataset\n",
    "import zipfile # To extract the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "And can create the data directory that will hold the dataset: `../data/`, by using the `makedirs` function from the `os` module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Ensure the data directory exists\n",
    "data_dir = '../data/'\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, since in the `~/.kaggle/` folder we have saved our kaggle credentials (mine are not commited to this repository) the `kaggle.api.dataset_download_files` function uses it automatically to authenticate with the api. \n",
    "\n",
    "Once we define the dataset identifier as `dataset = 'arashnic/fitbit'` the function accesses to the dataset and downloads it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use Kaggle API to download the dataset\n",
    "dataset = 'arashnic/fitbit'  # The dataset identifier on Kaggle\n",
    "kaggle.api.dataset_download_files(dataset, path=data_dir, unzip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the file has been downloaded, It can be unzipped as follows:\n",
    "\n",
    "* First the paths of where the file is and where it is going to be extracted are defined: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zip_file_path = '../data/fitbit.zip'\n",
    "extract_to_path = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then, the zip ifle is extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully unzipped the files, we can take a look to what we are dealing with, by printing the structure of the files within the `../data/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the structure of the ../data/ directory\n",
    "\n",
    "def print_directory_structure(root_dir, indent=''):\n",
    "    for item in os.listdir(root_dir):\n",
    "        item_path = os.path.join(root_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"{indent}üìÅ {item}/\")\n",
    "            print_directory_structure(item_path, indent + '    ')\n",
    "        else:\n",
    "            print(f\"{indent}üìÑ {item}\")\n",
    "\n",
    "# Define the root directory\n",
    "root_directory = '../data'\n",
    "\n",
    "# Print the directory structure\n",
    "print(f\"Directory structure of {root_directory}:\")\n",
    "print_directory_structure(root_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    " \n",
    "There are different kinds of data in these folder, one sample from march 12 to april 11 of 2016, and other from april 12 to may 12 of 2016.\n",
    "\n",
    "We will first assess all data files present in the folder of the first month, checking for missing values would be great first step. Also, since there are several datetime or date data, printing the first date value of each file will allow us to understand the granularity of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>NaN Indices</th>\n",
       "      <th>First Datetime Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityMinute</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityHour</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/13/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityDate</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityHour</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityDay</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityHour</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/13/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityHour</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityMinute</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityDay</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityMinute</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>Fat</td>\n",
       "      <td>65</td>\n",
       "      <td>[1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>Date</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>5/2/2016 11:59:59 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityHour</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityDay</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityMinute</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>Time</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 7:21:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>date</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 2:47:30 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>ActivityHour</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/13/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>../data/mturkfitbit_export_4.12.16-5.12.16/Fit...</td>\n",
       "      <td>SleepDay</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>4/12/2016 12:00:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 File          Column  \\\n",
       "0   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...  ActivityMinute   \n",
       "1   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...    ActivityHour   \n",
       "2   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...    ActivityDate   \n",
       "3   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...    ActivityHour   \n",
       "4   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...     ActivityDay   \n",
       "5   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...    ActivityHour   \n",
       "6   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...    ActivityHour   \n",
       "7   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...  ActivityMinute   \n",
       "8   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...     ActivityDay   \n",
       "9   ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...  ActivityMinute   \n",
       "10  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...             Fat   \n",
       "11  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...            Date   \n",
       "12  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...    ActivityHour   \n",
       "13  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...     ActivityDay   \n",
       "14  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...  ActivityMinute   \n",
       "15  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...            Time   \n",
       "16  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...            date   \n",
       "17  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...    ActivityHour   \n",
       "18  ../data/mturkfitbit_export_4.12.16-5.12.16/Fit...        SleepDay   \n",
       "\n",
       "    Missing Values                                        NaN Indices  \\\n",
       "0                0                                                 []   \n",
       "1                0                                                 []   \n",
       "2                0                                                 []   \n",
       "3                0                                                 []   \n",
       "4                0                                                 []   \n",
       "5                0                                                 []   \n",
       "6                0                                                 []   \n",
       "7                0                                                 []   \n",
       "8                0                                                 []   \n",
       "9                0                                                 []   \n",
       "10              65  [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "11               0                                                 []   \n",
       "12               0                                                 []   \n",
       "13               0                                                 []   \n",
       "14               0                                                 []   \n",
       "15               0                                                 []   \n",
       "16               0                                                 []   \n",
       "17               0                                                 []   \n",
       "18               0                                                 []   \n",
       "\n",
       "     First Datetime Value  \n",
       "0   4/12/2016 12:00:00 AM  \n",
       "1   4/13/2016 12:00:00 AM  \n",
       "2               4/12/2016  \n",
       "3   4/12/2016 12:00:00 AM  \n",
       "4               4/12/2016  \n",
       "5   4/13/2016 12:00:00 AM  \n",
       "6   4/12/2016 12:00:00 AM  \n",
       "7   4/12/2016 12:00:00 AM  \n",
       "8               4/12/2016  \n",
       "9   4/12/2016 12:00:00 AM  \n",
       "10                   None  \n",
       "11   5/2/2016 11:59:59 PM  \n",
       "12  4/12/2016 12:00:00 AM  \n",
       "13              4/12/2016  \n",
       "14  4/12/2016 12:00:00 AM  \n",
       "15   4/12/2016 7:21:00 AM  \n",
       "16   4/12/2016 2:47:30 AM  \n",
       "17  4/13/2016 12:00:00 AM  \n",
       "18  4/12/2016 12:00:00 AM  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory = '../data/mturkfitbit_export_4.12.16-5.12.16/Fitabase Data 4.12.16-5.12.16/'  # Replace with your directory path\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Function to read and process each file\n",
    "def process_file(filepath):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Get the filename\n",
    "    filename = os.path.basename(filepath)\n",
    "    \n",
    "    # Identify columns with missing values\n",
    "    missing_values = df.isna().sum()\n",
    "    missing_columns = missing_values[missing_values > 0]\n",
    "    \n",
    "    if not missing_columns.empty:\n",
    "        for col in missing_columns.index:\n",
    "            nan_indices = df[df[col].isna()].index.tolist()\n",
    "            results.append({\n",
    "                'File': filepath,\n",
    "                'Column': col,\n",
    "                'Missing Values': missing_columns[col],\n",
    "                'NaN Indices': nan_indices,\n",
    "                'First Datetime Value': None\n",
    "            })\n",
    "    \n",
    "    # Identify datetime columns and print the first value\n",
    "    datetime_columns = df.select_dtypes(include=['datetime64', 'object']).columns\n",
    "    for col in datetime_columns:\n",
    "        try:\n",
    "            first_value = df[col].dropna().iloc[0]\n",
    "            results.append({\n",
    "                'File': filepath,\n",
    "                'Column': col,\n",
    "                'Missing Values': 0,\n",
    "                'NaN Indices': [],\n",
    "                'First Datetime Value': first_value\n",
    "            })\n",
    "        except IndexError:\n",
    "            results.append({\n",
    "                'File': filepath,\n",
    "                'Column': col,\n",
    "                'Missing Values': 0,\n",
    "                'NaN Indices': [],\n",
    "                'First Datetime Value': 'Empty or NaN'\n",
    "            })\n",
    "\n",
    "# Iterate through all CSV files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        process_file(filepath)\n",
    "\n",
    "# Convert the results to a DataFrame and display it\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
