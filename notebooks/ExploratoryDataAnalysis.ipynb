{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitbit Data Analysis\n",
    "\n",
    "## Introduction\n",
    "This notebook aims to explore and analyze the Fitbit dataset. The dataset contains various CSV files with information on daily activities, calories burned, heart rate, sleep patterns, and more. We will start by listing the directory structure of the dataset, then proceed to load and inspect some key CSV files. Basic statistics and visualizations will be generated to understand the data better.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Import Libraries](#Import-Libraries)\n",
    "2. [List Directory Structure](#List-Directory-Structure)\n",
    "3. [Read CSV File](#Read-CSV-File)\n",
    "4. [Basic Statistics](#Basic-Statistics)\n",
    "5. [Check Missing Values](#Check-Missing-Values)\n",
    "6. [Visualize Data](#Visualize-Data)\n",
    "7. [Main Execution](#Main-Execution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Kaggle Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository includes a GitHub Actions workflow that continuously tests the process of connecting to the Kaggle API, via github secrets to pass username and key securely as environment variables, and then checks if the files are correctly downloaded, unzipped and imported to python using pandas.\n",
    "\n",
    "To do some work and then replicate it in the workflow, we are going to do an analogue operation.\n",
    "\n",
    "First we will have to install the kaggle API, if it is not installed already: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will import The following libraries: \n",
    "\n",
    "* `os`  \n",
    "* `KaggleApi`\n",
    "* `load_dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from dotenv import load_dotenv\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I don't want you, the reader of this notebook, to know my Kaggle credentials, we will use the `os` module function `getenv` to retrieve these two environment variables: 'KAGGLE_USERNAME' and 'KAGGLE_KEY'.\n",
    "\n",
    " These environment variables are set by a local .env file that is included in the .gitignore, so it is no comitted and you can't see it :-)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "kaggle_username = os.getenv('KAGGLE_USERNAME')\n",
    "kaggle_key = os.getenv('KAGGLE_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check really quick whether or not these variables are empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kaggle_username is None or kaggle_key is None:\n",
    "    raise ValueError(\"Kaggle credentials are not set in the environment variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already Have a way to authenticate, we can now connect to the Kaggle API and download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authentication with kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download the files included in the dataset website as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dataset\n",
    "dataset = 'arashnic/fitbit'\n",
    "\n",
    "# Downloading the dataset\n",
    "api.dataset_download_files(dataset, path='./data', unzip=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
